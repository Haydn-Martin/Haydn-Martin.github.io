 # What AI Isn't


Definitional intro sentence: playing fast and loose with the concept of "AI" here, essentially
meaning LLMs, such that the two concepts can pretty much be used interchangeably, although
most of this stuff will apply to a broader array of LLM-adjacent concepts.

So, then, AI/LLMs: work best in dense distribution with a large sample size to draw from.

Practical consequence: when you want to know about how to join two pandas dataframes,
who was the prime minister in 1975, or how to put up a shelf, an LLM will be able to tell you.

Anything that is well-understood, and well-documented, will be within AI's remit. Usually.

---

And these answers will be consistent, because, although non-deterministic, these models
are statistical in nature. Meaning: if there are 1,000,000 examples of explaining gravity,
your currently-favourite LLM will likely be able to explain gravity. Bad example but you
understand the point.

You'll never really drift too far out of dense sample space
(prompting, base models, temperature adjustment, etc. aside).
You'll always get an
output that is 90% consistent in these domains. It's this weird accuracy level between
deterministic code and natural anthropic (the word, not the company) variance.

Which is perfect when you're asking for answers to relatively simple questions.

But it can cause issues. The lack of determinism can be a nightmare in something
like software or a product.

---

You won't get an output that's really wrong, but you probably won't get one that's
right (or even thought-provoking) in a non-consensus way. No consistent errors,
but no bangers, either.

Which, again, is fine, and good, and desirable, in some (most?) circumstances.

But, well, it's a bit...boring, isn't it? I want my LLM to go batshit once in a while.
I'd pay extra.

This may seem like a trivial point but this is part of the reason why AI isn't good at writing
or vlogging or being entertaining in general.

Because the output is from dense distribution. It isn't creative. It can't make self-directed
conjectures about the world. It has no curiosity,
no sense for what is interesting and no intrinsic drive to explore it.

Another reason for this is that we just don't seem to care when humans aren't involved. There
isn't much demand for bot vs. bot chess. There won't be much demand for AI writing, either.
